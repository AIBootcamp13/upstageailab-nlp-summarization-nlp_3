{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이: 2165\n",
      "평균 길이: 406.08\n",
      "중간값: 369.0\n",
      "최대 길이: 376\n",
      "평균 길이: 85.79\n",
      "중간값: 80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 모든 열(Columns) 다 보기\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 모든 행(Rows) 다 보기\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)  # 또는 원하는 최대값\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/train.csv\")\n",
    "\n",
    "df.tail()\n",
    "\n",
    "#df.value_counts('topic')\n",
    "df['summary'].str.len().max()\n",
    "\n",
    "\n",
    "# 1. 최대 길이 구하기\n",
    "maxlen = df['summary'].str.len().max()\n",
    "\n",
    "# 2. 최대 길이 row(혹은 여러 개)를 출력\n",
    "max_rows = df[df['summary'].str.len() == maxlen]\n",
    "max_rows\n",
    "\n",
    "char_lengths = df['dialogue'].str.len()\n",
    "print(f'최대 길이: {char_lengths.max()}')\n",
    "print(f'평균 길이: {char_lengths.mean():.2f}')\n",
    "print(f'중간값: {char_lengths.median()}')\n",
    "\n",
    "char_lengths = df['summary'].str.len()\n",
    "print(f'최대 길이: {char_lengths.max()}')\n",
    "print(f'평균 길이: {char_lengths.mean():.2f}')\n",
    "print(f'중간값: {char_lengths.median()}')\n",
    "\n",
    "#dialogue: 2165, summary:376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이: 2165\n",
      "평균 길이: 406.08\n",
      "중간값: 369.0\n",
      "최대 길이: 376\n",
      "평균 길이: 85.79\n",
      "중간값: 80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 모든 열(Columns) 다 보기\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 모든 행(Rows) 다 보기\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)  # 또는 원하는 최대값\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/train.csv\")\n",
    "\n",
    "df.tail()\n",
    "\n",
    "#df.value_counts('topic')\n",
    "df['summary'].str.len().max()\n",
    "\n",
    "\n",
    "# 1. 최대 길이 구하기\n",
    "maxlen = df['summary'].str.len().max()\n",
    "\n",
    "# 2. 최대 길이 row(혹은 여러 개)를 출력\n",
    "max_rows = df[df['summary'].str.len() == maxlen]\n",
    "max_rows\n",
    "\n",
    "char_lengths = df['dialogue'].str.len()\n",
    "print(f'최대 길이: {char_lengths.max()}')\n",
    "print(f'평균 길이: {char_lengths.mean():.2f}')\n",
    "print(f'중간값: {char_lengths.median()}')\n",
    "\n",
    "char_lengths = df['summary'].str.len()\n",
    "print(f'최대 길이: {char_lengths.max()}')\n",
    "print(f'평균 길이: {char_lengths.mean():.2f}')\n",
    "print(f'중간값: {char_lengths.median()}')\n",
    "\n",
    "#dialogue: 2165, summary:376"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 1. 기본 라이브러리 불러오기\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 3. 데이터 로드 (src/data)\n",
    "train_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/train.csv\"\n",
    "new_train_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/new_train.csv\"\n",
    "test_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/test.csv\"\n",
    "dev_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/dev.csv\"\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_path, encoding=\"utf-8\")  # or cp949 if needed\n",
    "#new_train = pd.read_csv(new_train_path, encoding=\"utf-8\")  # or cp949 if needed\n",
    "test = pd.read_csv(test_path, encoding=\"utf-8\")\n",
    "dev = pd.read_csv(dev_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ train.csv shape: (12457, 4)\n",
      "✅ new_train.csv shape: (24439, 5)\n",
      "✅ test.csv shape: (499, 2)\n",
      "✅ dev.csv shape: (499, 4)\n",
      "\n",
      "📌 train 컬럼 목록: ['fname', 'dialogue', 'summary', 'topic']\n",
      "\n",
      "📌 train 샘플:\n",
      "      fname  \\\n",
      "0  train_0   \n",
      "1  train_1   \n",
      "2  train_2   \n",
      "3  train_3   \n",
      "4  train_4   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    dialogue  \\\n",
      "0  #Person1#: 안녕하세요, Mr. Smith. 저는 Dr. Hawkins입니다. 오늘 무슨 일로 오셨어요? \\n#Person2#: 건강검진을 받으려고 왔어요. \\n#Person1#: 네, 5년 동안 검진을 안 받으셨네요. 매년 한 번씩 받으셔야 해요. \\n#Person2#: 알죠. 특별히 아픈 데가 없으면 굳이 갈 필요가 없다고 생각했어요. \\n#Person1#: 음, 심각한 질병을 피하려면 미리 발견하는 게 제일 좋거든요. 본인을 위해서라도 매년 한 번은 오세요. \\n#Person2#: 알겠습니다. \\n#Person1#: 여기 좀 볼까요. 눈과 귀는 괜찮으시네요. 깊게 숨 한 번 쉬어보세요. Mr. Smith, 담배 피우세요? \\n#Person2#: 네. \\n#Person1#: 담배가 폐암하고 심장병의 주된 원인인 거 아시죠? 끊으셔야 해요. \\n#Person2#: 수백 번 시도했는데, 도저히 습관이 안 끊어져요. \\n#Person1#: 음, 도움 될만한 수업과 약물들이 있습니다. 가시기 전에 더 정보를 드릴게요. \\n#Person2#: 네, 고맙습니다, 의사 선생님.   \n",
      "1                                                                                                                    #Person1#: 안녕하세요, Mrs. Parker. 잘 지내셨나요?\\n#Person2#: 안녕하세요, Dr. Peters. 잘 지내고 있어요. Ricky랑 저희 둘 다 백신 맞으러 왔어요.\\n#Person1#: 알겠습니다. 백신 기록을 보니 Ricky는 소아마비, 파상풍, 그리고 B형 간염 예방접종을 받았네요. 지금 14개월이라 A형 간염, 수두, 홍역 예방접종을 맞아야 해요.\\n#Person2#: 풍진과 유행성이하선염은요?\\n#Person1#: 지금은 이 정도만 맞고, 몇 주 후에 나머지를 할 수 있어요.\\n#Person2#: 좋아요. 그리고 저도 파상풍 부스터가 필요할 것 같아요. 마지막으로 맞은 지 아마 15년은 된 것 같아요!\\n#Person1#: 기록을 확인해서 간호사에게 부스터도 맞출 수 있도록 할게요. 이제 Ricky 팔 꽉 잡아주세요, 좀 따끔할 수 있어요.   \n",
      "2                                                                                                                                                                                                                                                          #Person1#: 저기요, 열쇠 세트 본 적 있어요?\\n#Person2#: 어떤 종류의 열쇠요?\\n#Person1#: 열쇠 다섯 개랑 작은 발 장식이 달려 있어요.\\n#Person2#: 아, 안타깝네요! 못 봤어요.\\n#Person1#: 그럼, 같이 좀 찾아주실 수 있어요? 여긴 처음이라서요.\\n#Person2#: 물론이죠. 도와드릴게요.\\n#Person1#: 정말 친절하시네요.\\n#Person2#: 별거 아니에요. 이봐요, 찾았어요.\\n#Person1#: 아, 감사합니다! 어떻게 감사해야 할지 모르겠네요.\\n#Person2#: 천만에요.   \n",
      "3                                                                                                                                                                                                                                      #Person1#: 너 여자친구 있는 거 왜 말 안 했어?\\n#Person2#: 미안해, 네가 알고 있는 줄 알았어.\\n#Person1#: 그런데 사랑하는 사람 있다고 말했어야지.\\n#Person2#: 내가 안 했었나?\\n#Person1#: 안 했잖아.\\n#Person2#: 이제 말하잖아.\\n#Person1#: 맞아, 그런데 이전에 말할 수도 있었잖아.\\n#Person2#: 네가 관심 없을 줄 알았어.\\n#Person1#: 진심이야? 결혼할 거라는 말도 안 하다니 참.\\n#Person2#: 미안해, 별로 중요하지 않다고 생각했어.\\n#Person1#: 아, 남자들 다 똑같아!   \n",
      "4                                                                                                                                                                                                                                                                                #Person1#: 안녕, 오늘 너무 멋져 보이네요. 저랑 춤 한 곡 추실래요?\\n#Person2#: 고맙네요! 그런데 저는 춤 잘 못 춰요...\\n#Person1#: 괜찮아요. 제가 멋진 춤 동작 알려드릴게요. 제 이름은 Malik이에요.\\n#Person2#: 만나서 반가워요. 저는 Wen이고, 이 친구는 Nikki예요.\\n#Person1#: 기분 어때요? 친구랑 같이 춤춰도 될까요?\\n#Person2#: 괜찮아요, 대신 제 발을 밟아도 괜찮으시다면요.\\n#Person1#: 알겠어요. 좋아요! 가요!   \n",
      "\n",
      "                                                                            summary  \\\n",
      "0  Mr. Smith는 Dr. Hawkins에게 건강검진을 받으러 와서, 매년 검진 필요성을 안내받고 흡연 습관 개선을 위한 도움을 제안받았습니다.   \n",
      "1  Mrs. Parker가 Ricky와 함께 백신 접종을 위해 방문하였고, Dr. Peters는 Ricky에게 적절한 백신을 접종하도록 안내합니다.   \n",
      "2                            #Person1#은 열쇠 세트를 잃어버리고 #Person2#에게 찾는 것을 도와달라고 요청합니다.   \n",
      "3                     #Person1#은 #Person2#가 여자친구가 있고 결혼할 예정이라는 사실을 말하지 않아서 화가 났습니다.   \n",
      "4                       Malik은 Wen과 Nikki에게 춤을 제안하고, Wen은 발을 밟는 것을 감수하면 괜찮다고 응답합니다.   \n",
      "\n",
      "       topic  \n",
      "0       건강검진  \n",
      "1      백신 접종  \n",
      "2      열쇠 분실  \n",
      "3  여자친구와의 결혼  \n",
      "4       춤 제안  \n"
     ]
    }
   ],
   "source": [
    "# ✅ 4. 기본 정보 확인\n",
    "print(\"✅ train.csv shape:\", train.shape)\n",
    "print(\"✅ new_train.csv shape:\", new_train.shape)\n",
    "\n",
    "print(\"✅ test.csv shape:\", test.shape)\n",
    "print(\"✅ dev.csv shape:\", dev.shape)\n",
    "print(\"\\n📌 train 컬럼 목록:\", train.columns.tolist())\n",
    "print(\"\\n📌 train 샘플:\\n\", train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 5. 결측치 & 중복 확인\n",
    "print(\"\\n📌 결측치:\\n\", train.isnull().sum())\n",
    "print(\"\\n📌 중복 행 개수:\", train.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 text 길이 통계:\n",
      " count    12457.000000\n",
      "mean       406.083487\n",
      "std        197.566083\n",
      "min         84.000000\n",
      "25%        280.000000\n",
      "50%        369.000000\n",
      "75%        500.000000\n",
      "max       2165.000000\n",
      "Name: text_length, dtype: float64\n",
      "📌 토픽별 샘플 텍스트 (최대 5개까지 출력):\n",
      "\n",
      "🟡 [Topic: 'The Power of One' 책 읽기] 샘플 텍스트 (앞 300자):\n",
      "#Person1#: 무슨 책 읽고 있어? 어젯밤부터 그 책에서 눈을 떼지 않더라.\n",
      "#Person2#: 이 책 정말 재밌어. 도저히 손에서 뗄 수가 없어! 'The Power of One'이라고 해.\n",
      "#Person1#: 나도 그렇게 재밌는 책 읽은 지 오래됐어.\n",
      "#Person2#: 나도 그래. 첫 페이지부터 이 작가가 날 확 끌어들이더라고!\n",
      "#Person1#: 네가 다 읽고 나면 나도 볼 수 있어?\n",
      "#Person2#: 응, 지금 막 마지막 장 읽고 있는데 진짜 손에 땀을 쥐게 돼.\n",
      "#Person1#: 아무 얘기도 하지 마. 나 혼자 \n",
      "\n",
      "🟡 [Topic: 100만 달러 사용 계획] 샘플 텍스트 (앞 300자):\n",
      "#Person1#: 너 만약에 100만 달러 받으면 뭐 할 거야?\n",
      "#Person2#: 음, 잘 모르겠어. 아마 차를 사지 않을까?\n",
      "#Person1#: 그거 좀 재미없어 보이는데.\n",
      "#Person2#: 그럼 넌 뭐 할 건데?\n",
      "#Person1#: 난 세계 일주 여행 갈 거야.\n",
      "#Person2#: 어디로 갈 건데?\n",
      "#Person1#: 첫 번째로 파리에 갈 거야. 파리에서 쇼핑하는 게 늘 꿈이었거든.\n",
      "#Person2#: 좋은 생각이네. 거기서 돈 좀 쓰면 되겠다.\n",
      "#Person1#: 응, 그리고 나서 로마에 갈 거야. 내가 이탈리아 음식을 \n",
      "\n",
      "🟡 [Topic: 13일 금요일 미신] 샘플 텍스트 (앞 300자):\n",
      "#Person1#: 금요일 13일이 불길하다는 건 말도 안 돼. 난 절대 믿지 않아. \n",
      "#Person2#: 그렇게 단정할 수는 없잖아.\n",
      "#Person1#: 왜 안 돼? 그런 건 전부 미신이야.\n",
      "#Person2#: 하지만 어떤 사람들은 이 기회를 이용해 사고를 일으키기도 해. '13일 금요일' 바이러스 들어본 적 있어? 이 바이러스는 금요일 13일마다 퍼지도록 설계됐어.\n",
      "#Person1#: 그건 알아. 하지만 그건 운이 나쁘다는 것과는 상관없어. 바이러스를 만든 사람들은 그냥 사람들을 조롱하려는 거겠지.\n",
      "\n",
      "🟡 [Topic: 13일의 금요일과 관련된 미신] 샘플 텍스트 (앞 300자):\n",
      "#Person1#: 13일의 금요일에 대한 얘기는 정말 어이없어. 난 전혀 믿지 않아.\n",
      "#Person2#: 그렇게 단정할 수는 없잖아.\n",
      "#Person1#: 왜 그래? 다 미신이라고. 그런데 어떤 사람들은 그걸 이용해서 문제를 만들기도 해. 컴퓨터에 '블랙 프라이데이' 바이러스 들어본 적 있어? 그건 매년 13일의 금요일마다 발동되도록 돼 있어.\n",
      "#Person2#: 나도 알아. 그런데 그게 불운과는 상관없잖아. 그 바이러스를 만든 사람들이 그냥 사람들을 놀리는 거지.\n",
      "\n",
      "🟡 [Topic: 1920년대 오르골] 샘플 텍스트 (앞 300자):\n",
      "#Person1#: 옛날 오르골을 찾고 있어요.\n",
      "#Person2#: 저희가 좋은 컬렉션을 가지고 있어요. 어떤 시대를 찾고 계시나요?\n",
      "#Person1#: 1920년대에 만들어진 게 있나요?\n",
      "#Person2#: 여섯 개가 있습니다.\n",
      "#Person1#: 그중에 춤추는 피규어가 있는 게 있나요?\n",
      "#Person2#: 사실, 두 개가 춤추는 피규어가 있어요.\n",
      "#Person1#: 그거 정말 좋네요. 이걸로 할게요.\n",
      "#Person2#: 좋은 선택이에요. 저도 그게 더 좋아요.\n",
      "#Person1#: 그럼, 이 제품에 보증이 있나요?\n",
      "#Person2\n"
     ]
    }
   ],
   "source": [
    "# ✅ 6. 텍스트 길이 통계 분석\n",
    "train['text_length'] = train['dialogue'].apply(len)\n",
    "print(\"\\n📌 text 길이 통계:\\n\", train['text_length'].describe())\n",
    "\n",
    "print(\"📌 토픽별 샘플 텍스트 (최대 5개까지 출력):\")\n",
    "unique_topics = sorted(train[\"topic\"].unique())[:5]  # 너무 많으면 제한\n",
    "\n",
    "for topic in unique_topics:\n",
    "    sample_text = train[train[\"topic\"] == topic][\"dialogue\"].values[0][:300]\n",
    "    print(f\"\\n🟡 [Topic: {topic}] 샘플 텍스트 (앞 300자):\\n{sample_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#Person7#', '#CardNumber#', '#Person1#', '#Person6#', '#Person4#', '#Alex#', '#Person3#', '#Address#', '#Kristin#', '#Liliana#', '#Price#', '#Bob#', '#PassportNumber#', '#PhoneNumber#', '#CarNumber#', '#Person2#', '#Email#', '#SSN#', '#DateOfBirth#', '#PersonName#', '#Person5#', '#Name#'}\n"
     ]
    }
   ],
   "source": [
    "# ✅ 7. 스페셜 토큰\n",
    "import re\n",
    "import ast\n",
    "\n",
    "def reg_masking(text):\n",
    "  pattern = r\"#\\w+#\"  # ## 사이의 값을 추출하는 정규식 패턴\n",
    "  masked = re.findall(pattern, text)\n",
    "  return masked\n",
    "\n",
    "train_set = train['dialogue'].apply(lambda x:str(set(reg_masking(x))))\n",
    "set_train = train_set.apply(ast.literal_eval)\n",
    "\n",
    "test_set = test['dialogue'].apply(lambda x:str(set(reg_masking(x))))\n",
    "set_test = test_set.apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "# 모든 set을 하나로 합치기\n",
    "all_elements =  set().union(*set_train).union(*set_test)\n",
    "print(all_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "39.99244919270624\n",
      "161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12449"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# KoBART 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "\n",
    "def getTokenSize(text):\n",
    "\n",
    "    # 토큰화 후 토큰 수 계산\n",
    "    tokens = tokenizer(text)\n",
    "    token_count = len(tokens['input_ids'])\n",
    "\n",
    "    \n",
    "    \"\"\" if(token_count >= 700):\n",
    "        print(\"*\"*20)\n",
    "        print(f\"토큰 수: {token_count}\")\n",
    "        print(f\"text: {text}\") \"\"\"\n",
    "        \n",
    "    return token_count  \n",
    "\n",
    "token_sizes = train['summary'].apply(getTokenSize).tolist()       \n",
    "\n",
    "tmp = [ tok for tok in token_sizes if tok >= 10]\n",
    "\n",
    "print(min(tmp))\n",
    "print(sum(tmp)/ len(tmp))\n",
    "print(max(tmp))\n",
    "len(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  \n",
    "\n",
    "from src.data.backtranslation_augmentor import BackTranslationAugmentor\n",
    "\n",
    "# 증강기 초기화\n",
    "augmentor = BackTranslationAugmentor(use_gpu=True)\n",
    "\n",
    "# 단일 텍스트 백번역 테스트\n",
    "test_text = \"\"\"#Person1#: 네, 저희가 현재 8층에 있는데, 다른 건물 6층으로 이사하려고 해요. 그곳까지 약 15킬로미터 정도 되거든요.\"\"\"\n",
    "result = augmentor.back_translate(test_text)\n",
    "print(f\"원본: {test_text}\")\n",
    "print(f\"백번역: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/train.csv\"\n",
    "test_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/test.csv\"\n",
    "dev_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/dev.csv\"\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_path, encoding=\"utf-8\")  # or cp949 if needed\n",
    "test = pd.read_csv(test_path, encoding=\"utf-8\")\n",
    "dev = pd.read_csv(dev_path, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "\n",
    "from src.data.backtranslation_augmentor import BackTranslationAugmentor\n",
    "\n",
    "# 증강기 초기화\n",
    "augmentor = BackTranslationAugmentor(use_gpu=True)\n",
    "result = augmentor.augment_dialogue_data(train.to_dict('records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/train.csv\"\n",
    "test_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/test.csv\"\n",
    "dev_path = r\"/data/ephemeral/home/work/python/upstageailab-nlp-summarization-nlp_3/data/raw/dev.csv\"\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_path, encoding=\"utf-8\")  # or cp949 if needed\n",
    "test = pd.read_csv(test_path, encoding=\"utf-8\")\n",
    "dev = pd.read_csv(dev_path, encoding=\"utf-8\")\n",
    "\n",
    "# 가장 간단하고 효과적인 방법\n",
    "paraphraser = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"psyche/KoT5-paraphrase-generation\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def augment_with_paraphrase(train_data, ratio=0.3):\n",
    "    \"\"\"3줄로 끝나는 데이터 증강\"\"\"\n",
    "    \n",
    "    augmented = train_data.copy()\n",
    "    sample_size = int(len(train_data) * ratio)\n",
    "    selected = random.sample(range(len(train_data)), sample_size)\n",
    "    \n",
    "    for idx in selected:\n",
    "        original = train_data[idx]['dialogue']\n",
    "        \n",
    "        try:\n",
    "            paraphrased = paraphraser(f\"paraphrase: {original}\", \n",
    "                                    max_new_tokens=400,      # max_length 제거, 크기 증가\n",
    "                                    do_sample=True,\n",
    "                                    top_p=0.9,              # temperature 대신 top_p 사용\n",
    "                                    top_k=50,               # 다양성 제어\n",
    "                                    repetition_penalty=1.1,  # 반복 방지\n",
    "                                    num_return_sequences=1)[0]['generated_text']\n",
    "            \n",
    "            augmented.append({\n",
    "                'dialogue': paraphrased,\n",
    "                'summary': train_data[idx]['summary'],\n",
    "                'fname': f'aug_{idx}',\n",
    "                'topic': train_data[idx].get('topic', '')\n",
    "            })\n",
    "            print(\"원본:\")\n",
    "            print(original)\n",
    "            print(\"생성:\")\n",
    "            print(paraphrased)\n",
    "            print(f\"증강 완료: {len(augmented)}/{len(train_data) + sample_size}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# 사용법 (한 줄!)\n",
    "final_train_data = augment_with_paraphrase(train.to_dict('records'), ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# 1. 모델 로드 (Hugging Face Pipeline 사용)\n",
    "try:\n",
    "    paraphraser = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"psyche/KoT5-paraphrase-generation\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    print(\"✅ ainize/kobart-paraphrase 모델 로딩 성공!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 모델 로딩 실패: {e}\")\n",
    "    # 다른 대안 모델 시도 필요\n",
    "\n",
    "# 2. 패러프레이징 함수\n",
    "def paraphrase_with_kobart(text: str) -> str:\n",
    "    \"\"\"KoBART 기반의 안정적인 패러프레이징\"\"\"\n",
    "    try:\n",
    "        # KoBART 모델은 특별한 프롬프트 없이도 잘 동작합니다.\n",
    "        result = paraphraser(\n",
    "            text,\n",
    "            max_new_tokens =512,        # 생성될 문장의 최대 길이\n",
    "            do_sample=True,\n",
    "            temperature=0.8,       # 적당한 다양성\n",
    "            top_p=0.9,             # 높은 품질의 토큰 선택\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        return result[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        print(f\"패러프레이징 중 오류 발생: {e}\")\n",
    "        return text # 실패 시 원본 반환\n",
    "\n",
    "# 3. 테스트\n",
    "test_dialogue = \"\"\"#Person1#: 도와드릴까요, 손님?\n",
    "#Person2#: 일반유로 가득 채워 주세요.\n",
    "#Person1#: 배터리 점검해 드릴까요?\n",
    "#Person2#: 아니요, 괜찮아요. 급해서요.\n",
    "#Person1#: 차 준비됐습니다.\n",
    "#Person2#: 좋습니다! 얼마죠?\n",
    "#Person1#: 250위안입니다.\n",
    "#Person2#: 꽤 비싸네요.\n",
    "#Person1#: 유가가 좀 올랐어요.\"\"\"\n",
    "\n",
    "paraphrased_text = paraphrase_with_kobart(test_dialogue)\n",
    "\n",
    "print(\"\\n--- 결과 비교 ---\")\n",
    "print(f\"원본:\\n{test_dialogue}\")\n",
    "print(f\"\\n패러프레이징 결과:\\n{paraphrased_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DialogueParaphraser:\n",
    "    \"\"\"\n",
    "    화자 정보를 완벽하게 보존하면서 대화를 패러프레이징하는 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.paraphraser = None\n",
    "        self.model_name = \"psyche/KoT5-paraphrase-generation\" # 사용하시려는 모델\n",
    "        \n",
    "        try:\n",
    "            print(f\"'{self.model_name}' 모델 로딩 시도 중...\")\n",
    "            self.paraphraser = pipeline(\n",
    "                \"text2text-generation\",\n",
    "                model=self.model_name,\n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "            print(f\"✅ '{self.model_name}' 모델 로딩 성공!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로딩 실패: {e}\")\n",
    "            # 로딩 실패 시 대안 모델 시도\n",
    "            self.model_name = \"gogamza/kobart-summarization\"\n",
    "            print(f\"대안 모델 '{self.model_name}' 로딩 시도 중...\")\n",
    "            self.paraphraser = pipeline(\n",
    "                \"summarization\",\n",
    "                model=self.model_name,\n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "            print(f\"✅ 대안 모델 '{self.model_name}' 로딩 성공!\")\n",
    "\n",
    "\n",
    "    def paraphrase_dialogue(self, dialogue: str) -> str:\n",
    "        \"\"\"\n",
    "        대화 구조를 보존하며 안전하게 패러프레이징합니다.\n",
    "        \"\"\"\n",
    "        # 1. 정규표현식을 사용해 화자 태그와 발화 내용을 정확히 분리합니다.\n",
    "        speaker_pattern = r'(#(?:Person|개인)\\d+#:)'\n",
    "        parts = re.split(speaker_pattern, dialogue)\n",
    "        \n",
    "        segments = []\n",
    "        # parts 리스트는 [ '', '#Person1#:', ' 발화 내용1 ', '#Person2#:', ' 발화 내용2' ] 형태로 나옵니다.\n",
    "        for i in range(1, len(parts), 2):\n",
    "            speaker_tag = parts[i]\n",
    "            utterance = parts[i+1].strip()\n",
    "            if utterance:\n",
    "                segments.append((speaker_tag, utterance))\n",
    "\n",
    "        paraphrased_segments = []\n",
    "        for speaker_tag, utterance in segments:\n",
    "            try:\n",
    "                # 2. 순수한 발화 내용(utterance)만 모델에 전달합니다.\n",
    "                #    모델이 'summarization'일 경우를 대비해 태스크 이름을 확인합니다.\n",
    "                \n",
    "                # text2text-generation 모델 사용\n",
    "                result = self.paraphraser(\n",
    "                    utterance,\n",
    "                    max_new_tokens=512,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.8,          # 더 높은 온도로 창의성 증가\n",
    "                    top_k=50,                 # top_k 값을 설정하여 다양성 확보\n",
    "                    repetition_penalty=1.2,   # 반복을 줄여 새로운 표현 유도\n",
    "                    num_beams=1,              # 빔 서치 대신 샘플링에 집중\n",
    "                    num_return_sequences=1\n",
    "                )\n",
    "                paraphrased_utterance = result[0]['generated_text']\n",
    "\n",
    "                # 3. 패러프레이징된 결과에 원래의 화자 태그를 다시 붙여줍니다.\n",
    "                paraphrased_segments.append(f\"{speaker_tag} {paraphrased_utterance}\")\n",
    "\n",
    "            except Exception:\n",
    "                # 패러프레이징 실패 시, 안전하게 원본을 사용합니다.\n",
    "                paraphrased_segments.append(f\"{speaker_tag} {utterance}\")\n",
    "        \n",
    "        # 4. 개행문자(\\n)로 각 발화를 연결하여 최종 대화를 만듭니다.\n",
    "        return \"\\n\".join(paraphrased_segments)\n",
    "    \n",
    "    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"의미 기반 유사도 계산 (기존 Jaccard 대신)\"\"\"\n",
    "        \n",
    "        # 모델이 없다면 초기화\n",
    "        if not hasattr(self, 'similarity_model'):\n",
    "            print(\"유사도 측정 모델 로딩 (최초 1회)...\")\n",
    "            self.similarity_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
    "        \n",
    "        # 문장을 임베딩 벡터로 변환\n",
    "        embeddings = self.similarity_model.encode([text1, text2])\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        vec1 = embeddings[0]\n",
    "        vec2 = embeddings[1]\n",
    "        \n",
    "        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        \n",
    "        return similarity\n",
    "\n",
    "try:\n",
    "    # 1. 클래스 인스턴스 생성\n",
    "    final_paraphraser = DialogueParaphraser()\n",
    "\n",
    "    # 2. 문제가 발생했던 원본 대화\n",
    "    test_dialogue = \"\"\"#Person1#: Mr. King, 제가 도와드릴 일 있나요?\n",
    "#Person2#: 내일 아침에 상하이로 떠납니다. 계산은 언제 해야 하나요?\n",
    "#Person1#: 오늘 저녁에 계산하셔도 괜찮으신가요?\n",
    "#Person2#: 괜찮습니다. 돈은 어디 가서 내야 하나요?\n",
    "#Person1#: 저희 호텔 로비에 있는 수납 데스크에서 하시면 됩니다.\n",
    "#Person2#: 저녁식사 전까지 계산서 준비해 주시겠어요?\n",
    "#Person1#: 알겠습니다. 동행하신 분도 상하이로 함께 가시나요?\n",
    "#Person2#: 아니요, 그는 이곳에 이틀 더 머물 예정입니다. 방은 계속 사용할 수 있게 해주세요.\n",
    "#Person1#: 한 장으로 계산서를 준비할까요, 아니면 두 개로 나눌까요?\n",
    "#Person2#: 두 개로 나눠 주세요.\n",
    "#Person1#: 알겠습니다. 저녁에 계산서 준비해 드리겠습니다.\n",
    "#Person2#: 여섯 시쯤에 계산서 받을 수 있을까요?\n",
    "#Person1#: 문제없습니다. 그런데 저희 호텔에 대해 의견이 있으신가요?\n",
    "#Person2#: 여기서 편안하게 지냈습니다. 서비스가 훌륭하네요. 아주 만족합니다.\n",
    "#Person1#: 칭찬 감사합니다. 언제든 다시 오십시오.\n",
    "#Person2#: 네, 그럴게요.\"\"\"\n",
    "\n",
    "    # 3. 패러프레이징 실행\n",
    "    paraphrased_text = final_paraphraser.paraphrase_dialogue(test_dialogue)\n",
    "\n",
    "    # 4. 결과 확인\n",
    "    print(\"\\n\" + \"=\"*20 + \" 최종 결과 \" + \"=\"*20)\n",
    "    print(\"### 원본 대화 ###\")\n",
    "    print(test_dialogue)\n",
    "    print(\"\\n### 패러프레이징 결과 (구조 보존됨) ###\")\n",
    "    print(paraphrased_text)\n",
    "    print(\"=\"*53)\n",
    "    print(\"similarity:\"+ str(final_paraphraser.calculate_semantic_similarity(test_dialogue, paraphrased_text)))    \n",
    "except Exception as e:\n",
    "    print(f\"최종 실행 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psyche/KoT5-paraphrase의 실제 제한 확인\n",
    "def check_model_max_length():\n",
    "    from transformers import AutoTokenizer\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"psyche/KoT5-paraphrase-generation\")\n",
    "    \n",
    "    print(f\"모델 최대 길이: {tokenizer.model_max_length}\")\n",
    "    # 일반적으로 512 또는 1024 출력\n",
    "    \n",
    "    return tokenizer.model_max_length\n",
    "\n",
    "# 확인 실행\n",
    "actual_max = check_model_max_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('EbanLee/kobart-summary-v3')\n",
    "model = BartForConditionalGeneration.from_pretrained('EbanLee/kobart-summary-v3')\n",
    "\n",
    "def summarize_dialogue(text, max_length=150):\n",
    "    # 입력 길이가 1024를 초과하면 자동으로 잘림\n",
    "    inputs = tokenizer(text, \n",
    "                      return_tensors=\"pt\", \n",
    "                      max_length=1024, \n",
    "                      truncation=True)\n",
    "    \n",
    "    # 요약 생성\n",
    "    summary_ids = model.generate(inputs['input_ids'],\n",
    "                                num_beams=4,\n",
    "                                max_length=max_length,\n",
    "                                early_stopping=True)\n",
    "    \n",
    "    # 디코딩\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# 사용\n",
    "dialogue = \"\"\"#Person1#: 안녕, Andrew! 안녕 ...? Andrew. \n",
    "#Person2#: 뭐? \n",
    "#Person1#: Andrew. \n",
    "#Person2#: 뭐? 무슨 일이야? \n",
    "#Person1#: 너한테 무슨 일이야? \n",
    "#Person2#: 내 머리 얘기하는 거야? 내 머리 마음에 들어? \n",
    "#Person1#: 어, 무슨 말인지 알잖아, Andrew. 솔직하게 말할까? \n",
    "#Person2#: 뭐? \n",
    "#Person1#: 좋아. Andrew, 너 크리스마스 때 본 이후로 엄청 쪘어. 무슨 일이 있었던 거야? \n",
    "#Person2#: 너 왜 항상 그렇게 솔직해? \n",
    "#Person1#: 난 누나잖아. 내가 ... 뭐야? 너보다 세 살 많으니까 말하고 싶으면 솔직할 수 있어. 게다가, 너 항상 나한테 그런 말 하곤 했잖아. 나 어릴 때 너 나한테 뚱뚱하다고 그랬잖아. \n",
    "#Person2#: 아, 그래, 솔직히 말해서, 응, 어제부터 삶을 바꾸기 시작했어. \n",
    "#Person1#: 오, 잘됐네! \n",
    "#Person2#: 나 와후 다이어트 중이야. \n",
    "#Person1#: 뭐? 와후 다이어트가 뭐야? \n",
    "#Person2#: 아, 설명하기 너무 복잡해. 며칠 전에 스팸메일에서 정보 찾았거든 ... \n",
    "#Person1#: 뭐? 스팸메일을 읽어? 아무도 스팸메일 안 읽잖아. \n",
    "#Person2#: ... 그리고 등록했거든, 490달러밖에 안 들었어. \n",
    "#Person1#: 진심이야? \n",
    "#Person2#: 응. \n",
    "#Person1#: 490달러씩? 매달이야 아니면 매주야? \n",
    "#Person2#: 아, 그건 확인 안 해봤는데 ... 하지만, 하지만, 하지만 ... 그런 것 같아. \n",
    "#Person1#: 잘 들어, 너 사기당하는 것 같아, 그거 진짜로 이상해. 나 뚱뚱하지 않으니까 믿어. ... 체중 감량하고 싶으면 제대로 해야 돼. \n",
    "#Person2#: 그럼, 어떻게? \n",
    "#Person1#: 좋아, 오케이. \n",
    "#Person2#: 봐봐, 내 운동화 저기 있잖아. \n",
    "#Person1#: Andrew. 아직 박스에 그대로네. \n",
    "#Person2#: 그게 ... \n",
    "#Person1#: 한 번도 안 신었네. 운동을 해야 해, 운동은 좋아. 근데 제대로 먹는 법도 배워야 해. 예를 들어, 적당한 양을 먹어야 해. 그리고 가족 모임에서 항상 하던 것처럼 두 접시 세 접시 먹으면 안 돼. \n",
    "#Person2#: 그럼, 큰 접시 써야겠네! \n",
    "#Person1#: Andrew! 그건 안돼. 다음. \n",
    "#Person2#: 다음? \n",
    "#Person1#: 첫째로 적은 양을 먹어야 해 \n",
    "#Person2#: 오케이. \n",
    "#Person1#: 아침에 균형 잡힌 아침 식사를 해야 해 \n",
    "#Person2#: 그건 해. \n",
    "#Person1#: 그리고 그다음에 작은 식사를 하루 종일 해야지. 아침을 안 먹으면 점심이나 저녁에 과식하게 되잖아. \n",
    "#Person2#: 음 ... \n",
    "#Person1#: 그리고 밤늦게 먹지 마. \n",
    "#Person2#: 뭐? 뭐같이? \n",
    "#Person1#: 많은 사람들이 늦은 밤에 간식을 먹고 싶어 하는데, 그게 대부분 칼로리가 많은 것들이야. 아이스크림 같은 거, 활동을 안 해서 그걸 살로 저장하거든. 버려야 해 ... 오 마이 갓! \n",
    "#Person2#: 뭐? \n",
    "#Person1#: 너 냉동실에 아이스크림밖에 없어! 다 버려야 해? \n",
    "#Person2#: 그건 저칼로리 아이스크림이야. \n",
    "#Person1#: 저칼 ... 아니야, 저칼로리가 아냐. 여기 봐봐. Andrew! 너 먹는 게 아이스크림밖에 없네. \n",
    "#Person2#: 그럼 뭐, 뭐? \n",
    "#Person1#: 또 다른 건 뭐 먹어? \n",
    "#Person2#: 글쎄 ... \n",
    "#Person1#: 진짜로? 아이스크림만 먹어? 아, 아, 아. 쓰레기통 봐봐. 매일 맥도날드 가네. 매일 패스트푸드 먹는다고? \n",
    "#Person2#: 그게 ... \n",
    "#Person1#: 패스트푸드 줄여야 해. 맥도날드 매니저 이름을 알 정도고, 페이스북에서 베프라면, 패스트푸드를 너무 많이 먹는 거야. \n",
    "#Person2#: 이거 진짜 힘들겠는데. \n",
    "#Person1#: 그래, 그럴 거야. 근데 과일과 채소를 많이 먹어야 해. \n",
    "#Person2#: 아, 그래. \n",
    "#Person1#: 설탕을 확 줄여야 해. 매일 다섯 갤런씩 마시는 콜라 같은 달달한 음료 안 돼. \n",
    "#Person2#: 다섯 갤런 안 마셔. \n",
    "#Person1#: 그럼 그 컵 사이즈 좀 봐. 몇 번이나 리필해? \n",
    "#Person2#: 그럼 마실 게 뭐야? \n",
    "#Person1#: 물! \n",
    "#Person2#: 물? \n",
    "#Person1#: 정말 몸에 좋아. \n",
    "#Person2#: 아, 이거 힘들겠어. \n",
    "#Person1#: 어쩌면 힘들지.\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(dialogue)\n",
    "print(f\"요약: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 1. 텍스트 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['text_length'], bins=50, kde=True, color='royalblue')\n",
    "plt.title(\"텍스트 길이 분포\", fontsize=16)\n",
    "plt.xlabel(\"문자 수\", fontsize=13)\n",
    "plt.ylabel(\"샘플 수\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_aware_removal(text):\n",
    "    \"\"\"문맥을 고려한 태그 처리\"\"\"\n",
    "    \n",
    "    # HTML 태그 특징: 소문자, 알려진 태그명\n",
    "    html_pattern = r'<(div|p|span|a|img|br|hr|h[1-6]|ul|ol|li|table|tr|td|strong|b|em|i)[^>]*>'\n",
    "    text = re.sub(html_pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 닫는 태그\n",
    "    text = re.sub(r'</(div|p|span|a|h[1-6]|ul|ol|li|table|tr|td|strong|b|em|i)>', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 화자 태그는 그대로 두거나 변환\n",
    "    # <이름> 패턴을 이름: 으로 변환\n",
    "    text = re.sub(r'<([A-Za-z가-힣\\s]+)>', r'\\1:', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "test_cases = [\n",
    "    \"<The Witch> 마법을 사용합니다\",\n",
    "    \"<Player1> 안녕하세요\",\n",
    "    \"<div class='content'>HTML 내용</div>\",\n",
    "    \"<p>문단입니다</p>\", \n",
    "    \"<a href='link'>링크</a>\",\n",
    "    \"<System> 시스템 메시지\",\n",
    "    \"<br>\",\n",
    "    \"<img src='image.jpg'>\",\n",
    "    \"<span>텍스트</span>\"\n",
    "]\n",
    "\n",
    "print(\"컨텍스트 기반 처리 결과:\")\n",
    "for text in test_cases:\n",
    "    result = context_aware_removal(text)\n",
    "    print(f\"'{text}' → '{result}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_repetitions(text):\n",
    "    \"\"\"실제로 매치되는 전체 문자열 확인\"\"\"\n",
    "    #pattern = r'(.)\\1{2,}'\n",
    "    pattern = r'([^\\d])\\1{2,}'\n",
    "    \n",
    "    # finditer로 매치 위치와 내용 모두 확인\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    \n",
    "    print(f\"총 {len(matches)}개의 반복 패턴 발견:\")\n",
    "    for i, match in enumerate(matches):\n",
    "        start, end = match.span()\n",
    "        matched_text = text[start:end]\n",
    "        repeated_char = match.group(1)\n",
    "        \n",
    "        print(f\"{i+1}. '{matched_text}' (위치: {start}-{end}, 문자: '{repeated_char}')\")\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "test['dialogue'].apply(find_all_repetitions)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 1. 텍스트 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['text_length'], bins=50, kde=True, color='royalblue')\n",
    "plt.title(\"텍스트 길이 분포\", fontsize=16)\n",
    "plt.xlabel(\"문자 수\", fontsize=13)\n",
    "plt.ylabel(\"샘플 수\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ✅ 2. 요약 텍스트 길이 분포 (summary)\n",
    "train['summary_len'] = train['summary'].apply(len)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['summary_len'], bins=50, kde=True, color='salmon')\n",
    "plt.title(\"요약 텍스트 길이 분포\")\n",
    "plt.xlabel(\"문자 수\")\n",
    "plt.ylabel(\"샘플 수\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"summary_length_distribution.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ✅ 3. 레이블 분포 (상위 100개)\n",
    "top_topics = train['topic'].value_counts().nlargest(100)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_topics.index, y=top_topics.values, palette=\"Set3\")\n",
    "plt.title(\"Topic 상위 100개 분포\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top100_topic_distribution.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ✅ 4. 고유 토픽 개수 출력\n",
    "print(\"고유 Topic 개수:\", train['topic'].nunique())\n",
    "\n",
    "# ✅ 5. 특수문자/숫자 포함 비율\n",
    "import re\n",
    "\n",
    "def count_special_ratio(text):\n",
    "    return len(re.findall(r\"[^\\w\\s]\", text)) / len(text)\n",
    "\n",
    "train['special_ratio'] = train['dialogue'].apply(count_special_ratio)\n",
    "print(\"평균 특수문자 비율:\", train['special_ratio'].mean())\n",
    "\n",
    "# ✅ 6. tokenizer 기준 토큰 길이\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/kobart\") # 요약 task에 적합\n",
    "train['dialogue_token_len'] = train['dialogue'].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
    "train['summary_token_len'] = train['summary'].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(train['dialogue_token_len'], color=\"dodgerblue\", label=\"입력\")\n",
    "sns.histplot(train['summary_token_len'], color=\"tomato\", label=\"요약\")\n",
    "plt.title(\"Token 길이 분포\")\n",
    "plt.xlabel(\"Token 수\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"token_length_comparison.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# 요약 vs 입력 길이 비율 분포\n",
    "# → 평균값이 너무 높거나 낮으면 모델이 잘 못 배움\n",
    "#→ 보통 3~8 사이 분포가 안정적\n",
    "train['dialogue_len'] = train['dialogue'].apply(len)\n",
    "train['summary_len'] = train['summary'].apply(len)\n",
    "train['length_ratio'] = train['dialogue_len'] / train['summary_len']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['length_ratio'], bins=50, kde=True, color=\"purple\")\n",
    "plt.title(\"입력 길이 / 요약 길이 비율 분포\", fontsize=16)\n",
    "plt.xlabel(\"비율 (dialogue / summary)\")\n",
    "plt.ylabel(\"샘플 수\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"dialogue_summary_ratio.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# tokenizer 적용 후 입력/요약 토큰 수\n",
    "# → max_seq_len, max_target_len 설정 근거가 됨\n",
    "# → ex) 95% quantile 기준으로 자르는 게 좋음\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/kobart\")\n",
    "\n",
    "train['input_token_len'] = train['dialogue'].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
    "train['output_token_len'] = train['summary'].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train['input_token_len'], color=\"dodgerblue\", label=\"입력\", kde=True)\n",
    "sns.histplot(train['output_token_len'], color=\"tomato\", label=\"요약\", kde=True)\n",
    "plt.title(\"Token 길이 분포 (tokenizer 적용 후)\", fontsize=16)\n",
    "plt.xlabel(\"토큰 수\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"token_length_distribution.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# topic별 요약 길이 차이 확인\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='topic', y='summary_len', data=train[train['topic'].isin(train['topic'].value_counts().nlargest(10).index)])\n",
    "plt.title(\"상위 10개 Topic별 요약 길이 분포\", fontsize=16)\n",
    "plt.xticks(rotation=60)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"summary_length_per_topic.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# 중복 대화 탐지\n",
    "duplicate_dialogues = train['dialogue'].duplicated().sum()\n",
    "print(f\"📌 중복된 dialogue 수: {duplicate_dialogues}개 ({duplicate_dialogues/train.shape[0]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 모든 열(Columns) 다 보기\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 모든 행(Rows) 다 보기\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)  # 또는 원하는 최대값\n",
    "\n",
    "df.topic.unique()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "​",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "​",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "​",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "​",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "​",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "​",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
