<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# 🎯 Dialogue Summarization AI 프로젝트 로드맵

## 📋 프로젝트 개요

일상 대화를 바탕으로 요약문을 생성하는 AI 모델을 개발하는 경진대회 프로젝트입니다. 249개의 대화문을 입력으로 받아 해당하는 요약문을 생성하는 것이 목표입니다.[^1]

## 🗺️ 단계별 프로젝트 로드맵

### 1단계: 📊 데이터 이해 및 탐색 (EDA)

**⏱️ 예상 소요시간: 2-3일**

#### 🔍 주요 작업

- 제공된 대화문과 요약문 데이터셋 분석
- 대화문의 길이, 구조, 주제 분포 파악
- 요약문의 특성 및 패턴 분석
- 데이터 품질 검증


#### 💡 어드바이스

- 대화문의 평균 길이와 요약문의 압축 비율을 계산해보세요
- 대화의 유형(회의, 일상대화 등)별 특성을 파악하세요
- 요약문이 대화의 핵심을 얼마나 잘 담고 있는지 몇 개 샘플을 직접 읽어보세요


#### ⚠️ 주의점

- 데이터에 불완전하거나 누락된 부분이 있는지 반드시 확인
- 개인정보나 민감한 정보가 포함되어 있지 않은지 검토


### 2단계: 🧹 데이터 전처리

**⏱️ 예상 소요시간: 3-4일**

#### 🔍 주요 작업

- 텍스트 정규화 (특수문자, 공백 처리)
- 대화 턴 구분 및 화자 정보 처리
- 불필요한 노이즈 제거
- 토큰화 및 인코딩 방식 결정


#### 💡 어드바이스

- 한국어 특성을 고려한 전처리 파이프라인 구축
- KoNLPy, mecab 등 한국어 형태소 분석기 활용 검토
- 대화의 맥락을 유지하면서 전처리하는 것이 중요


#### ⚠️ 주의점

- 과도한 전처리로 대화의 자연스러운 흐름을 해치지 않도록 주의
- 요약문과 대화문의 전처리 일관성 유지


### 3단계: 🤖 모델 선택 및 설계

**⏱️ 예상 소요시간: 2-3일**

#### 🔍 주요 작업

- 베이스라인 모델 선정 (BART, T5, GPT 계열 등)
- 한국어 사전 훈련 모델 검토 (KoBERT, KoGPT 등)
- 모델 아키텍처 설계
- 하이퍼파라미터 초기 설정


#### 💡 어드바이스

- 요약 태스크에 특화된 모델부터 시작하세요 (BART, T5 추천)
- 한국어 성능이 검증된 모델을 우선적으로 고려
- 작은 모델부터 시작해서 점진적으로 확장


#### ⚠️ 주의점

- 모델 크기와 컴퓨팅 리소스의 균형 고려
- 추론 시간과 정확도의 트레이드오프 고려


### 4단계: 🏋️ 모델 훈련

**⏱️ 예상 소요시간: 5-7일**

#### 🔍 주요 작업

- 학습/검증 데이터 분할
- 모델 훈련 파이프라인 구축
- 학습률, 배치 크기 등 하이퍼파라미터 튜닝
- 모델 성능 모니터링


#### 💡 어드바이스

- 조기 종료(Early Stopping) 기법 활용
- 학습 곡선을 지속적으로 모니터링
- 여러 시드값으로 실험하여 안정성 확인
- Gradient Accumulation으로 메모리 효율성 개선


#### ⚠️ 주의점

- 과적합 방지를 위한 정규화 기법 적용
- GPU 메모리 부족 시 배치 크기 조절
- 체크포인트 저장으로 학습 중단 상황 대비


### 5단계: 📈 모델 평가 및 검증

**⏱️ 예상 소요시간: 3-4일**

#### 🔍 주요 작업

- ROUGE, BLEU 등 자동 평가 지표 계산
- 정성적 평가 (사람이 직접 요약 품질 검토)
- 다양한 대화 유형별 성능 분석
- 에러 케이스 분석


#### 💡 어드바이스

- 여러 평가 지표를 종합적으로 활용
- 실제 요약문과 예측 요약문을 직접 비교해보세요
- 길이별, 주제별 성능 차이 분석


#### ⚠️ 주의점

- 자동 평가 지표만으로 판단하지 말고 실제 품질도 확인
- 훈련 데이터에 없는 새로운 패턴에 대한 일반화 성능 검증


### 6단계: 🔧 모델 개선 및 최적화

**⏱️ 예상 소요시간: 4-5일**

#### 🔍 주요 작업

- 앙상블 기법 적용
- 후처리 규칙 개발
- 모델 경량화 (필요시)
- 추가 데이터 활용 검토


#### 💡 어드바이스

- 서로 다른 모델의 앙상블로 성능 향상 시도
- 요약문의 길이나 스타일 일관성을 위한 후처리 적용
- 외부 데이터나 데이터 증강 기법 활용 고려


#### ⚠️ 주의점

- 과도한 최적화로 인한 복잡성 증가 주의
- 실제 추론 환경에서의 속도와 안정성 고려


### 7단계: 📤 최종 제출 준비

**⏱️ 예상 소요시간: 1-2일**

#### 🔍 주요 작업

- 249개 테스트 데이터에 대한 예측 수행
- CSV 형식으로 결과 정리
- 제출 파일 형식 검증
- 최종 점검 및 제출


#### 💡 어드바이스

- 제출 형식을 정확히 확인하고 샘플 제출해보세요
- 예측 결과의 품질을 최종적으로 검토
- 백업 모델 준비 (메인 모델 오류 시 대비)


#### ⚠️ 주의점

- 제출 마감 시간 엄수
- 파일 형식과 컬럼명 정확성 재확인
- 예상치 못한 에러에 대한 예외 처리


## 🛠️ 추천 도구 및 라이브러리

### 🐍 Python 라이브러리

- **transformers**: Hugging Face 모델 활용
- **pandas**: 데이터 처리
- **torch/tensorflow**: 딥러닝 프레임워크
- **konlpy**: 한국어 자연어 처리
- **rouge-score**: 평가 지표 계산


### 💻 개발 환경

- **GPU**: RTX 3080 이상 권장
- **RAM**: 16GB 이상
- **저장공간**: 50GB 이상


## 🎯 성공을 위한 핵심 포인트

### ✅ DO

- 📝 체계적인 실험 로그 작성
- 🔄 지속적인 성능 모니터링
- 🤝 커뮤니티 참여 및 정보 공유
- 📊 다양한 접근법 시도


### ❌ DON'T

- 🚫 처음부터 복잡한 모델 사용 금지
- 🚫 데이터 분석 없이 바로 모델링 시작
- 🚫 단일 평가 지표에만 의존
- 🚫 제출 직전까지 모델 수정


## 📅 전체 일정 요약

| 단계 | 기간 | 핵심 목표 |
| :-- | :-- | :-- |
| 1단계 | 2-3일 | 📊 데이터 완전 이해 |
| 2단계 | 3-4일 | 🧹 효과적인 전처리 |
| 3단계 | 2-3일 | 🤖 적절한 모델 선택 |
| 4단계 | 5-7일 | 🏋️ 안정적인 모델 훈련 |
| 5단계 | 3-4일 | 📈 객관적인 성능 평가 |
| 6단계 | 4-5일 | 🔧 성능 극대화 |
| 7단계 | 1-2일 | 📤 완벽한 제출 |

**총 예상 기간: 20-28일** ⏰

프로젝트 성공을 위해 각 단계를 꼼꼼히 진행하시고, 막히는 부분이 있으면 언제든 질문하세요! 화이팅! 🚀

<div style="text-align: center">⁂</div>

[^1]: 11.html

